#!/usr/bin/env python3
"""
Teste do Sistema com LLM Agent
=============================

Este script testa especificamente se o GoogleLLMAgent estÃ¡ sendo chamado
pelo OrchestratorAgent.
"""

from __future__ import annotations
import sys
from pathlib import Path

# Adiciona o diretÃ³rio raiz do projeto ao PYTHONPATH
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

from src.agent.orchestrator_agent import OrchestratorAgent
from src.utils.logging_config import get_logger

logger = get_logger(__name__)

def test_llm_integration():
    """Testa se o LLM Agent estÃ¡ sendo utilizado."""
    print("\nğŸ§ª TESTE DE INTEGRAÃ‡ÃƒO LLM AGENT")
    print("=" * 50)
    
    # Inicializar orquestrador
    print("ğŸ”§ Inicializando orquestrador...")
    try:
        orchestrator = OrchestratorAgent()
        agents = list(orchestrator.agents.keys())
        print(f"âœ… Agentes disponÃ­veis: {', '.join(agents)}")
        
        # Verificar se LLM estÃ¡ disponÃ­vel
        if "llm" in agents:
            print("âœ… Google LLM Agent estÃ¡ disponÃ­vel!")
        else:
            print("âš ï¸ Google LLM Agent NÃƒO estÃ¡ disponÃ­vel")
            return
            
    except Exception as e:
        print(f"âŒ Erro na inicializaÃ§Ã£o: {e}")
        return
    
    # Testes especÃ­ficos para acionar LLM
    test_queries = [
        "explique os padrÃµes de fraude",
        "qual sua conclusÃ£o sobre os dados?",
        "dÃª uma recomendaÃ§Ã£o baseada na anÃ¡lise",  
        "interprete os resultados",
        "faÃ§a um sumÃ¡rio detalhado",
    ]
    
    print(f"\nğŸ¯ Testando {len(test_queries)} consultas LLM:")
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n--- Teste {i}/5 ---")
        print(f"â“ Consulta: '{query}'")
        
        try:
            result = orchestrator.process(query)
            
            # Debug: ver toda a estrutura da resposta
            print(f"ğŸ“‹ Estrutura resposta: {result.keys() if isinstance(result, dict) else type(result)}")
            
            # Verificar se LLM foi usado  
            metadata = result.get("metadata", {})
            orchestrator_meta = metadata.get("orchestrator", {})
            agents_used = orchestrator_meta.get("agents_used", metadata.get("agents_used", []))
            llm_used = metadata.get("llm_used", False)
            
            print(f"ğŸ“ Tipo identificado: {metadata.get('query_type', 'unknown')}")
            print(f"ğŸ¤– Agentes usados: {agents_used}")
            print(f"ğŸ§  LLM usado: {llm_used}")
            
            if "llm" in agents_used or llm_used:
                print("âœ… LLM Agent foi utilizado!")
                content = result.get("content", "")
                if content:
                    print(f"ğŸ’¬ Resposta: {content[:100]}...")
                else:
                    print("âš ï¸ Resposta vazia")
            else:
                print("âš ï¸ LLM Agent NÃƒO foi utilizado")
                
        except Exception as e:
            print(f"âŒ Erro no teste: {e}")
    
    print(f"\nğŸ Teste concluÃ­do!")

def test_with_data_context():
    """Testa LLM com contexto de dados."""
    print("\nğŸ§ª TESTE LLM COM CONTEXTO DE DADOS")
    print("=" * 50)
    
    try:
        orchestrator = OrchestratorAgent()
        
        # Simular contexto de dados carregados
        context = {
            "file_path": "examples/dados_exemplo.csv",
            "data_info": {
                "rows": 1000,
                "columns": 7,
                "fraud_detected": 44
            }
        }
        
        llm_queries = [
            "interprete esses dados de fraude",
            "que conclusÃµes vocÃª tira?",
            "recomende prÃ³ximos passos"
        ]
        
        for query in llm_queries:
            print(f"\nâ“ Consulta com contexto: '{query}'")
            
            result = orchestrator.process(query, context=context)
            
            # Debug: ver estrutura completa
            metadata = result.get("metadata", {})
            orchestrator_meta = metadata.get("orchestrator", {})
            agents_used = orchestrator_meta.get("agents_used", metadata.get("agents_used", []))
            llm_used = metadata.get("llm_used", False)
            
            print(f"ğŸ¤– Agentes usados: {agents_used}")
            print(f"ğŸ§  LLM usado: {llm_used}")
            
            if "llm" in agents_used or llm_used:
                print("âœ… LLM processou consulta com contexto!")
                content = result.get("content", "")
                if content:
                    print(f"ğŸ’¬ Resposta: {content[:200]}...")
            else:
                print("âš ï¸ LLM nÃ£o foi utilizado")
                
    except Exception as e:
        print(f"âŒ Erro no teste com contexto: {e}")

if __name__ == "__main__":
    test_llm_integration()
    test_with_data_context()