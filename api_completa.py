#!/usr/bin/env python3
"""
API Completa - EDA AI Minds com Sistema Multiagente
==================================================

# Inicializa√ß√£o de agentes
orchestrator = None
csv_agent = None

if MULTIAGENT_AVAILABLE:
    try:
        if ORCHESTRATOR_AVAILABLE:
            orchestrator = OrchestratorAgent()
            logger.info("Orquestrador inicializado")
        
        if CSV_AGENT_AVAILABLE:
            csv_agent = EmbeddingsAnalysisAgent()
            logger.info("CSV Agent inicializado")
            
        logger.info("Sistema multiagente inicializado com sucesso")
    except Exception as e:
        logger.error(f"Erro ao inicializar sistema multiagente: {e}")
        orchestrator = None
        csv_agent = None
        MULTIAGENT_AVAILABLE = Falsea com integra√ß√£o ao sistema multiagente:
- Orquestrador central para coordenar agentes
- An√°lise real de dados CSV com IA
- Detec√ß√£o de fraude inteligente
- Sistema de embeddings e RAG
- Mem√≥ria persistente
"""

from fastapi import FastAPI, HTTPException, UploadFile, File, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import uvicorn
import sys
import os
import io
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Optional
import logging
from pathlib import Path

# Adiciona o diret√≥rio raiz do projeto ao PYTHONPATH
root_dir = Path(__file__).parent
sys.path.insert(0, str(root_dir))

# Configurar logger antes de tudo
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# Importa o LLM Router
try:
    from src.llm.llm_router import LLMRouter, create_llm_with_routing, ComplexityLevel
    LLM_ROUTER_AVAILABLE = True
    logger.info("‚úÖ LLM Router carregado - roteamento inteligente ativo")
except Exception as e:
    LLM_ROUTER_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è LLM Router n√£o dispon√≠vel: {e}")

# Flags de disponibilidade
MULTIAGENT_AVAILABLE = False
ORCHESTRATOR_AVAILABLE = False
CSV_AGENT_AVAILABLE = False

# Imports do sistema multiagente (MODO SEGURO)
print("üîß Carregando sistema multiagente...")

try:
    from src.settings import GOOGLE_API_KEY, SUPABASE_URL, SUPABASE_KEY
    logger.info("‚úÖ Configura√ß√µes carregadas")
    
    if not GOOGLE_API_KEY:
        logger.warning("‚ö†Ô∏è GOOGLE_API_KEY n√£o configurado - modo limitado")
    
    MULTIAGENT_AVAILABLE = True
    
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Configura√ß√µes n√£o dispon√≠veis: {e}")
    MULTIAGENT_AVAILABLE = False

# Tentar carregar agentes (OPCIONAL - n√£o bloqueia a API)
orchestrator = None
csv_agent = None

if MULTIAGENT_AVAILABLE:
    # Modo seguro: carrega sem depend√™ncias problem√°ticas
    logger.info("ü§ñ Tentando carregar agentes...")
    try:
        # Importa apenas se necess√°rio
        import importlib.util
        
        # Verifica se o m√≥dulo existe sem import√°-lo
        orchestrator_spec = importlib.util.find_spec("src.agent.orchestrator_agent")
        if orchestrator_spec:
            logger.info("‚úÖ Orquestrador encontrado (carregamento lazy)")
            ORCHESTRATOR_AVAILABLE = True
        else:
            logger.warning("‚ö†Ô∏è Orquestrador n√£o encontrado")
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erro ao verificar agentes: {e}")

# Configura√ß√µes
MAX_FILE_SIZE = 999 * 1024 * 1024  # 999MB
PORT = 8001  # Porta diferente da API simples
API_TIMEOUT = 120  # Timeout de 120 segundos para opera√ß√µes longas

app = FastAPI(
    title="EDA AI Minds - API Completa",
    description="Sistema multiagente para an√°lise inteligente de dados CSV",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    timeout=API_TIMEOUT  # Timeout configur√°vel
)

# CORS para permitir requisi√ß√µes do frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelos Pydantic
class HealthResponse(BaseModel):
    status: str
    timestamp: str
    version: str = "2.0.0"
    message: str
    multiagent_status: bool
    agents_available: List[str]
    timeout_seconds: int = API_TIMEOUT

class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = "default"
    use_memory: Optional[bool] = True
    file_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    session_id: str
    timestamp: str
    agent_used: str
    analysis_type: Optional[str] = None
    confidence: Optional[float] = None
    llm_model: Optional[str] = None  # Modelo LLM usado
    complexity_level: Optional[str] = None  # N√≠vel de complexidade detectado

class FraudDetectionRequest(BaseModel):
    file_id: Optional[str] = None
    transaction_data: Optional[Dict[str, Any]] = None
    analysis_depth: Optional[str] = "comprehensive"  # basic, comprehensive, advanced

class FraudDetectionResponse(BaseModel):
    fraud_score: float
    risk_level: str  # low, medium, high, critical
    patterns_detected: List[str]
    recommendations: List[str]
    analysis_details: Dict[str, Any]
    processing_time: float

class CSVUploadResponse(BaseModel):
    file_id: str
    filename: str
    rows: int
    columns: int
    message: str
    analysis_ready: bool
    fraud_detection_available: bool

# Inicializa√ß√£o do sistema multiagente (LAZY LOADING)
# Os agentes ser√£o carregados apenas quando necess√°rio
orchestrator = None
csv_agent = None

logger.info(f"üéØ Status: MULTIAGENT={MULTIAGENT_AVAILABLE}, ORCHESTRATOR={ORCHESTRATOR_AVAILABLE}")
logger.info("‚úÖ API pronta para iniciar (agentes em modo lazy loading)")

# Storage tempor√°rio para dados carregados
uploaded_files = {}

def load_csv_by_file_id(file_id: str) -> Optional[pd.DataFrame]:
    """Carrega um DataFrame a partir do file_id"""
    try:
        if file_id in uploaded_files:
            file_info = uploaded_files[file_id]
            df = file_info.get('dataframe')
            if df is not None:
                logger.info(f"CSV carregado com sucesso: {file_id}")
                return df
            else:
                logger.warning(f"DataFrame n√£o encontrado para file_id: {file_id}")
                return None
        else:
            logger.warning(f"file_id n√£o encontrado: {file_id}")
            return None
    except Exception as e:
        logger.error(f"Erro ao carregar CSV: {e}")
        return None

def analyze_csv_data(df: pd.DataFrame, file_info: dict, message: str) -> str:
    """An√°lise contextual de dados CSV com insights inteligentes"""
    try:
        analysis = []
        
        # Informa√ß√µes b√°sicas do arquivo
        filename = file_info.get('filename', 'arquivo.csv')
        analysis.append(f"üìä **An√°lise do arquivo: {filename}**\n")
        
        # Dimens√µes dos dados
        rows, cols = df.shape
        analysis.append(f"üìà **Dimens√µes:** {rows:,} linhas x {cols} colunas\n")
        
        # Estat√≠sticas b√°sicas
        analysis.append("üìã **Resumo Estat√≠stico:**")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            stats = df[numeric_cols].describe()
            for col in numeric_cols[:3]:  # Primeiras 3 colunas num√©ricas
                mean_val = stats.loc['mean', col]
                std_val = stats.loc['std', col]
                analysis.append(f"   ‚Ä¢ {col}: M√©dia {mean_val:.2f}, Desvio {std_val:.2f}")
        
        analysis.append("")
        
        # An√°lise espec√≠fica para dados de cart√£o de cr√©dito/fraude
        # ‚úÖ FIX: Inicializar vari√°veis antes do bloco condicional
        fraud_col = None
        fraud_count = 0
        fraud_rate = 0.0
        
        fraud_keywords = ['fraud', 'class', 'amount', 'time']
        if any(keyword in df.columns.str.lower().tolist() for keyword in fraud_keywords):
            analysis.append("üîç **An√°lise de Fraude Detectada:**")
            
            # Verifica coluna de classe/fraude
            for col in df.columns:
                if 'class' in col.lower() or 'fraud' in col.lower():
                    fraud_col = col
                    break
            
            if fraud_col is not None:
                fraud_count = df[fraud_col].sum() if df[fraud_col].dtype in ['int64', 'float64'] else len(df[df[fraud_col] == 1])
                fraud_rate = (fraud_count / len(df)) * 100
                analysis.append(f"   ‚Ä¢ Taxa de fraude: {fraud_rate:.2f}% ({fraud_count:,} casos)")
                analysis.append(f"   ‚Ä¢ Transa√ß√µes leg√≠timas: {len(df) - fraud_count:,}")
            
            # An√°lise de valores
            if 'amount' in df.columns.str.lower().tolist():
                amount_col = [col for col in df.columns if 'amount' in col.lower()][0]
                avg_amount = df[amount_col].mean()
                max_amount = df[amount_col].max()
                analysis.append(f"   ‚Ä¢ Valor m√©dio: ${avg_amount:.2f}")
                analysis.append(f"   ‚Ä¢ Valor m√°ximo: ${max_amount:.2f}")
        
        analysis.append("")
        
        # Valores ausentes
        missing = df.isnull().sum()
        if missing.sum() > 0:
            analysis.append("‚ö†Ô∏è **Valores Ausentes:**")
            for col, count in missing[missing > 0].items():
                pct = (count / len(df)) * 100
                analysis.append(f"   ‚Ä¢ {col}: {count} ({pct:.1f}%)")
        else:
            analysis.append("‚úÖ **Dados Completos:** Nenhum valor ausente encontrado")
        
        analysis.append("")
        
        # Resposta contextual √† pergunta
        message_lower = message.lower()
        if 'fraude' in message_lower or 'fraud' in message_lower:
            analysis.append("üéØ **Resposta √† sua pergunta sobre fraude:**")
            if fraud_col is not None:
                analysis.append(f"   Os dados mostram {fraud_count:,} casos de fraude em {len(df):,} transa√ß√µes.")
                analysis.append(f"   Isso representa uma taxa de {fraud_rate:.2f}% de fraude no dataset.")
            else:
                analysis.append("   Este dataset n√£o parece conter uma coluna espec√≠fica de fraude.")
        
        elif 'estat√≠stica' in message_lower or 'm√©dia' in message_lower or 'resumo' in message_lower:
            analysis.append("üéØ **Estat√≠sticas principais:**")
            for col in numeric_cols[:2]:
                mean_val = df[col].mean()
                median_val = df[col].median()
                analysis.append(f"   ‚Ä¢ {col}: M√©dia {mean_val:.2f}, Mediana {median_val:.2f}")
        
        elif 'colunas' in message_lower or 'vari√°veis' in message_lower:
            analysis.append("üéØ **Informa√ß√µes sobre colunas:**")
            analysis.append(f"   Total de {len(df.columns)} colunas:")
            for i, col in enumerate(df.columns[:10]):  # Primeiras 10 colunas
                dtype = str(df[col].dtype)
                analysis.append(f"   {i+1}. {col} ({dtype})")
            if len(df.columns) > 10:
                analysis.append(f"   ... e mais {len(df.columns) - 10} colunas")
        
        return "\n".join(analysis)
        
    except Exception as e:
        logger.error(f"Erro na an√°lise CSV: {e}")
        return f"‚ùå Erro ao analisar os dados: {str(e)}"

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Verifica status da API e sistema multiagente"""
    agents_available = []
    
    if MULTIAGENT_AVAILABLE:
        agents_available = ["csv_analyzer", "embeddings_analyzer"]
        if orchestrator:
            agents_available.append("orchestrator")
    
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        message="API completa operacional com sistema multiagente",
        multiagent_status=MULTIAGENT_AVAILABLE,
        agents_available=agents_available
    )

@app.get("/health/detailed")
async def health_check_detailed():
    """Health check detalhado sem carregar agentes (evita timeout)"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0",
        "timeout_config": API_TIMEOUT,
        "components": {
            "multiagent_system": MULTIAGENT_AVAILABLE,
            "orchestrator_available": ORCHESTRATOR_AVAILABLE,
            "orchestrator_loaded": orchestrator is not None,
            "llm_router": LLM_ROUTER_AVAILABLE,
        },
        "performance": {
            "recommended_timeout_frontend": "120000",  # 120 segundos em ms
            "first_load_time": "60-90s (lazy loading)",
            "subsequent_requests": "2-10s"
        },
        "tips": [
            "Primeira requisi√ß√£o pode demorar at√© 90s (carrega todos os agentes)",
            "Requisi√ß√µes subsequentes s√£o mais r√°pidas (cache de agentes)",
            "Configure timeout do frontend para 120000ms (120s)",
            "Use /chat com file_id para an√°lise contextual de CSV"
        ]
    }

@app.post("/chat", response_model=ChatResponse)
async def chat_with_ai(request: ChatRequest):
    """Chat inteligente com sistema multiagente e an√°lise contextual de CSV"""
    global orchestrator  # Declarar no in√≠cio da fun√ß√£o
    
    try:
        start_time = datetime.now()
        session_id = request.session_id or "default"
        
        # üß† ROTEAMENTO INTELIGENTE DE LLM
        llm_config = None
        if LLM_ROUTER_AVAILABLE:
            # Prepara contexto para roteamento
            routing_context = {}
            if request.file_id and request.file_id in uploaded_files:
                file_info = uploaded_files[request.file_id]
                routing_context["dataset_size"] = {
                    "rows": file_info.get("rows", 0),
                    "columns": file_info.get("columns", 0)
                }
            
            # Detecta complexidade e seleciona modelo
            llm_config = create_llm_with_routing(request.message, routing_context)
            logger.info(f"üß† LLM Router: {llm_config['model_name']} (Complexidade: {llm_config['complexity_name']})")
            logger.info(f"   Temperature: {llm_config['temperature']}, Reasoning: {llm_config['reasoning']}")
        
        # üéØ AN√ÅLISE COM SISTEMA MULTIAGENTE
        # Verifica se h√° file_id para an√°lise contextual COM ORCHESTRATOR
        if request.file_id:
            if request.file_id not in uploaded_files:
                raise HTTPException(status_code=404, detail="Arquivo CSV n√£o encontrado")
            
            logger.info(f"ü§ñ Iniciando an√°lise multiagente para file_id: {request.file_id}")
            
            # Carrega o DataFrame espec√≠fico
            df = load_csv_by_file_id(request.file_id)
            if df is None:
                raise HTTPException(status_code=500, detail="Erro ao carregar dados do CSV")
            
            file_info = uploaded_files[request.file_id]
            
            # üöÄ CHAMA O ORQUESTRADOR COM CONTEXTO DO CSV
            if MULTIAGENT_AVAILABLE and ORCHESTRATOR_AVAILABLE:
                try:
                    # Carrega o orquestrador se ainda n√£o foi carregado
                    if orchestrator is None:
                        logger.info("üì¶ Carregando orquestrador dinamicamente...")
                        from src.agent.orchestrator_agent import OrchestratorAgent
                        orchestrator = OrchestratorAgent()
                        logger.info("‚úÖ Orquestrador carregado com sucesso")
                    
                    # Cria contexto enriquecido com informa√ß√µes do CSV
                    csv_context = f"""
                    Arquivo CSV carregado: {file_info['filename']}
                    Dimens√µes: {file_info['rows']} linhas x {file_info['columns']} colunas
                    Colunas dispon√≠veis: {', '.join(df.columns.tolist()[:10])}
                    
                    Pergunta do usu√°rio: {request.message}
                    
                    Por favor, analise os dados usando todos os agentes dispon√≠veis.
                    """
                    
                    logger.info("üß† Enviando para orquestrador com contexto CSV...")
                    result = orchestrator.process_query(
                        query=csv_context,
                        session_id=session_id,
                        use_memory=request.use_memory
                    )
                    
                    response_text = result.get('response', 'An√°lise multiagente conclu√≠da')
                    agent_used = result.get('agent_used', 'orchestrator')
                    analysis_type = result.get('analysis_type', 'multiagent_csv_analysis')
                    confidence = result.get('confidence', 0.95)
                    
                    logger.info(f"‚úÖ An√°lise multiagente conclu√≠da: {agent_used}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro ao usar orquestrador: {e}")
                    logger.info("‚ö†Ô∏è Fallback para an√°lise b√°sica")
                    # Fallback para an√°lise b√°sica
                    response_text = analyze_csv_data(df, file_info, request.message)
                    agent_used = "csv_basic_analyzer"
                    analysis_type = "csv_analysis_fallback"
                    confidence = 0.80
            else:
                # Sem orquestrador dispon√≠vel - usa an√°lise b√°sica
                logger.info("‚ö†Ô∏è Orquestrador n√£o dispon√≠vel - usando an√°lise b√°sica")
                response_text = analyze_csv_data(df, file_info, request.message)
                agent_used = "csv_basic_analyzer"
                analysis_type = "csv_analysis_basic"
                confidence = 0.75
            
        else:
            # Processamento sem arquivo espec√≠fico
            if not MULTIAGENT_AVAILABLE:
                raise HTTPException(
                    status_code=503,
                    detail="Sistema multiagente n√£o dispon√≠vel. Verifique configura√ß√µes."
                )
            
            logger.info("üí¨ Chat gen√©rico sem file_id")
            
            # Carrega orquestrador dinamicamente se necess√°rio
            if orchestrator is None and ORCHESTRATOR_AVAILABLE:
                try:
                    logger.info("üì¶ Carregando orquestrador dinamicamente...")
                    from src.agent.orchestrator_agent import OrchestratorAgent
                    orchestrator = OrchestratorAgent()
                    logger.info("‚úÖ Orquestrador carregado")
                except Exception as e:
                    logger.error(f"‚ùå Erro ao carregar orquestrador: {e}")
            
            if orchestrator and hasattr(orchestrator, 'process_query'):
                # Usa o orquestrador se dispon√≠vel
                result = orchestrator.process_query(
                    query=request.message,
                    session_id=session_id,
                    use_memory=request.use_memory
                )
            else:
                # Processa com l√≥gica simplificada
                result = process_message_simple(request.message, session_id)
            
            # Extrai informa√ß√µes do resultado
            response_text = result.get('response', 'Desculpe, n√£o consegui processar sua solicita√ß√£o.')
            agent_used = result.get('agent_used', 'orchestrator')
            analysis_type = result.get('analysis_type')
            confidence = result.get('confidence')
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Adiciona informa√ß√µes do LLM Router se dispon√≠vel
        llm_model_used = llm_config["model_name"] if llm_config else None
        complexity_detected = llm_config["complexity_name"] if llm_config else None
        
        logger.info(f"Chat processado em {processing_time:.2f}s por {agent_used}")
        if llm_model_used:
            logger.info(f"   LLM: {llm_model_used} | Complexidade: {complexity_detected}")
        
        return ChatResponse(
            response=response_text,
            session_id=session_id,
            timestamp=datetime.now().isoformat(),
            agent_used=agent_used,
            analysis_type=analysis_type,
            confidence=confidence,
            llm_model=llm_model_used,
            complexity_level=complexity_detected
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no chat: {e}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@app.post("/csv/upload", response_model=CSVUploadResponse)
async def upload_csv(file: UploadFile = File(...)):
    """Upload e processamento de arquivo CSV com prepara√ß√£o para an√°lise IA"""
    if not file.filename:
        raise HTTPException(status_code=400, detail="Nome do arquivo √© obrigat√≥rio")
        
    if file.size and file.size > MAX_FILE_SIZE:
        raise HTTPException(status_code=413, detail="Arquivo muito grande")
    
    if not file.filename.endswith('.csv'):
        raise HTTPException(status_code=400, detail="Apenas arquivos CSV s√£o aceitos")
    
    try:
        # L√™ o arquivo CSV
        content = await file.read()
        df = pd.read_csv(io.BytesIO(content))
        
        # Gera ID √∫nico para o arquivo
        file_id = f"csv_{int(datetime.now().timestamp())}_{file.filename.replace('.csv', '')}"
        
        # Armazena informa√ß√µes do arquivo
        uploaded_files[file_id] = {
            'filename': file.filename,
            'dataframe': df,
            'upload_date': datetime.now().isoformat(),
            'rows': len(df),
            'columns': len(df.columns)
        }
        
        # Verifica se √© um dataset de fraude (detecta colunas t√≠picas)
        fraud_columns = ['Class', 'isFraud', 'fraud', 'is_fraud', 'label']
        has_fraud_column = any(col in df.columns for col in fraud_columns)
        
        # Se o sistema multiagente est√° dispon√≠vel, processa o arquivo
        analysis_ready = False
        fraud_detection_available = False
        
        if MULTIAGENT_AVAILABLE and csv_agent:
            try:
                # Processa dados b√°sicos sempre
                analysis_ready = True
                fraud_detection_available = has_fraud_column
                logger.info(f"Arquivo {file.filename} processado pelo sistema multiagente")
            except Exception as e:
                logger.warning(f"Erro ao processar com sistema multiagente: {e}")
        
        logger.info(f"Upload conclu√≠do: {file.filename} ({len(df)} linhas, {len(df.columns)} colunas)")
        
        return CSVUploadResponse(
            file_id=file_id,
            filename=file.filename,
            rows=len(df),
            columns=len(df.columns),
            message="CSV carregado e processado com sucesso",
            analysis_ready=analysis_ready,
            fraud_detection_available=fraud_detection_available
        )
        
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao processar arquivo: {str(e)}")

@app.post("/fraud/detect", response_model=FraudDetectionResponse)
async def detect_fraud(request: FraudDetectionRequest):
    """Detec√ß√£o de fraude usando IA avan√ßada"""
    if not MULTIAGENT_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="Sistema de IA n√£o dispon√≠vel para detec√ß√£o de fraude"
        )
    
    start_time = datetime.now()
    
    try:
        # Monta query espec√≠fica para detec√ß√£o de fraude
        if request.file_id:
            if request.file_id not in uploaded_files:
                raise HTTPException(status_code=404, detail="Arquivo n√£o encontrado")
            
            file_info = uploaded_files[request.file_id]
            query = f"""
            AN√ÅLISE DE FRAUDE ESPECIALIZADA:
            
            Arquivo: {file_info['filename']}
            Dados: {file_info['rows']} transa√ß√µes, {file_info['columns']} caracter√≠sticas
            Profundidade: {request.analysis_depth}
            
            Por favor, execute uma an√°lise completa de detec√ß√£o de fraude:
            
            1. PADR√ïES SUSPEITOS:
               - Identifique transa√ß√µes com comportamento an√¥malo
               - Analise valores extremos e outliers
               - Detecte padr√µes temporais suspeitos
               
            2. SCORING DE RISCO:
               - Calcule score de fraude (0-100)
               - Classifique n√≠vel de risco
               - Identifique fatores de risco principais
               
            3. RECOMENDA√á√ïES:
               - A√ß√µes preventivas
               - Monitoramento sugerido
               - Regras de neg√≥cio recomendadas
            
            Forne√ßa uma an√°lise detalhada e estruturada.
            """
        else:
            # An√°lise de dados espec√≠ficos fornecidos
            query = f"""
            AN√ÅLISE DE FRAUDE EM TRANSA√á√ÉO ESPEC√çFICA:
            
            Dados da transa√ß√£o: {request.transaction_data}
            Profundidade: {request.analysis_depth}
            
            Analise esta transa√ß√£o espec√≠fica para detectar poss√≠vel fraude.
            """
        
        # Processa com o sistema dispon√≠vel
        if orchestrator and hasattr(orchestrator, 'process_query'):
            result = orchestrator.process_query(
                query=query,
                session_id=f"fraud_detection_{int(datetime.now().timestamp())}",
                use_memory=True
            )
        else:
            # An√°lise simplificada de fraude
            result = analyze_fraud_simple(request, uploaded_files)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Extrai informa√ß√µes estruturadas da resposta
        response_text = result.get('response', '')
        
        # Analisa a resposta para extrair m√©tricas estruturadas
        fraud_score = extract_fraud_score(response_text)
        risk_level = determine_risk_level(fraud_score)
        patterns_detected = extract_patterns(response_text)
        recommendations = extract_recommendations(response_text)
        
        analysis_details = {
            'agent_used': result.get('agent_used', 'orchestrator'),
            'confidence': result.get('confidence', 0.8),
            'analysis_method': 'multiagent_ai',
            'full_analysis': response_text,
            'processing_time': processing_time
        }
        
        logger.info(f"Detec√ß√£o de fraude conclu√≠da: score={fraud_score}, risco={risk_level}")
        
        return FraudDetectionResponse(
            fraud_score=fraud_score,
            risk_level=risk_level,
            patterns_detected=patterns_detected,
            recommendations=recommendations,
            analysis_details=analysis_details,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"Erro na detec√ß√£o de fraude: {e}")
        raise HTTPException(status_code=500, detail=f"Erro na an√°lise: {str(e)}")

@app.get("/csv/files")
async def list_files():
    """Lista arquivos CSV carregados"""
    files_list = []
    for file_id, info in uploaded_files.items():
        files_list.append({
            'file_id': file_id,
            'filename': info['filename'],
            'rows': info['rows'],
            'columns': info['columns'],
            'upload_date': info['upload_date']
        })
    
    return {
        'total': len(files_list),
        'files': files_list
    }

@app.get("/dashboard/metrics")
async def dashboard_metrics():
    """M√©tricas do dashboard"""
    total_files = len(uploaded_files)
    total_rows = sum(info['rows'] for info in uploaded_files.values())
    total_columns = sum(info['columns'] for info in uploaded_files.values())
    
    agents_status = {}
    if MULTIAGENT_AVAILABLE:
        agents_status = {
            'orchestrator': 'active' if orchestrator else 'inactive',
            'csv_agent': 'active' if csv_agent else 'inactive',
            'multiagent_system': 'operational'
        }
    else:
        agents_status = {'multiagent_system': 'unavailable'}
    
    return {
        'total_files': total_files,
        'total_rows': total_rows,
        'total_columns': total_columns,
        'status': 'operational' if MULTIAGENT_AVAILABLE else 'limited',
        'last_activity': datetime.now().isoformat(),
        'agents_status': agents_status,
        'fraud_detection': 'available' if MULTIAGENT_AVAILABLE else 'unavailable'
    }

# Fun√ß√µes auxiliares para processamento simplificado
def process_message_simple(message: str, session_id: str) -> Dict[str, Any]:
    """Processamento simplificado de mensagens quando orquestrador n√£o dispon√≠vel"""
    message_lower = message.lower()
    
    # Detecta tipo de an√°lise baseado na mensagem
    if any(word in message_lower for word in ["fraude", "fraud", "detec√ß√£o", "detectar"]):
        response = """üõ°Ô∏è **An√°lise de Fraude com IA:**

**Status:** Sistema multiagente ativo para detec√ß√£o avan√ßada

**Capacidades Dispon√≠veis:**
‚Ä¢ üß† An√°lise comportamental com IA
‚Ä¢ üîç Detec√ß√£o de padr√µes suspeitos
‚Ä¢ üìä Scoring de risco automatizado
‚Ä¢ üö® Alertas em tempo real
‚Ä¢ üìà An√°lise de tend√™ncias

**Para usar:**
1. Fa√ßa upload do seu arquivo CSV
2. Use o endpoint `/fraud/detect` para an√°lise completa
3. Configure alertas personalizados

O sistema est√° pronto para analisar seus dados!"""
        analysis_type = "fraud_detection"
        
    elif any(word in message_lower for word in ["csv", "dados", "an√°lise", "estat√≠stica"]):
        response = """üìä **An√°lise de Dados CSV:**

**Sistema Multiagente Ativo:**
‚Ä¢ ü§ñ Agentes especializados dispon√≠veis
‚Ä¢ üìà An√°lise estat√≠stica avan√ßada
‚Ä¢ üîç Detec√ß√£o de padr√µes e outliers
‚Ä¢ üìä Visualiza√ß√µes autom√°ticas
‚Ä¢ üß† Insights inteligentes com IA

**Como usar:**
1. Upload seu arquivo CSV via `/csv/upload`
2. Fa√ßa perguntas espec√≠ficas sobre os dados
3. Solicite an√°lises e visualiza√ß√µes

Pronto para analisar seus dados!"""
        analysis_type = "csv_analysis"
        
    else:
        response = """ü§ñ **EDA AI Minds - Sistema Multiagente:**

**Status:** ‚úÖ Operacional

**Agentes Dispon√≠veis:**
‚Ä¢ üìä Analisador de CSV
‚Ä¢ üõ°Ô∏è Detector de Fraude
‚Ä¢ üîç Sistema de Embeddings
‚Ä¢ üß† Processador de Linguagem Natural

**Comandos:**
‚Ä¢ "analisar dados" - An√°lise completa de CSV
‚Ä¢ "detectar fraude" - An√°lise de seguran√ßa
‚Ä¢ "ajuda" - Comandos dispon√≠veis

Como posso ajudar com seus dados?"""
        analysis_type = "general"
    
    return {
        'response': response,
        'agent_used': 'simplified_processor',
        'analysis_type': analysis_type,
        'confidence': 0.8,
        'session_id': session_id
    }

def analyze_fraud_simple(request: FraudDetectionRequest, files_data: Dict) -> Dict[str, Any]:
    """An√°lise simplificada de fraude quando orquestrador n√£o dispon√≠vel"""
    if request.file_id and request.file_id in files_data:
        file_info = files_data[request.file_id]
        df = file_info['dataframe']
        
        # An√°lise b√°sica estat√≠stica para detectar anomalias
        analysis_text = f"""üõ°Ô∏è **AN√ÅLISE DE FRAUDE - {file_info['filename']}**

**üìä Resumo dos Dados:**
‚Ä¢ Total de transa√ß√µes: {len(df):,}
‚Ä¢ Caracter√≠sticas analisadas: {len(df.columns)}
‚Ä¢ Dataset: {file_info['filename']}

**üîç An√°lise Estat√≠stica:**"""

        # Detecta colunas num√©ricas
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_cols:
            # An√°lise de outliers b√°sica
            outliers_detected = 0
            for col in numeric_cols[:3]:  # Analisa at√© 3 colunas
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                outliers = len(df[(df[col] < lower_bound) | (df[col] > upper_bound)])
                outliers_detected += outliers
                
                analysis_text += f"\n‚Ä¢ {col}: {outliers} outliers detectados"
        
        # Verifica se h√° coluna de classifica√ß√£o (fraude)
        fraud_columns = ['Class', 'isFraud', 'fraud', 'is_fraud', 'label']
        fraud_col = None
        for col in fraud_columns:
            if col in df.columns:
                fraud_col = col
                break
        
        if fraud_col is not None:
            fraud_count = df[fraud_col].sum() if df[fraud_col].dtype in ['int64', 'float64'] else len(df[df[fraud_col] == 1])
            fraud_rate = (fraud_count / len(df)) * 100
            analysis_text += f"\n\n**üö® Detec√ß√£o de Fraude:**"
            analysis_text += f"\n‚Ä¢ Transa√ß√µes fraudulentas: {fraud_count:,} ({fraud_rate:.2f}%)"
            analysis_text += f"\n‚Ä¢ Taxa de fraude: {'ALTA' if fraud_rate > 5 else 'MODERADA' if fraud_rate > 1 else 'BAIXA'}"
            
            fraud_score = min(95.0, fraud_rate * 10 + 30)
        else:
            analysis_text += f"\n\n**‚ö†Ô∏è An√°lise Baseada em Outliers:**"
            analysis_text += f"\n‚Ä¢ Total de outliers: {outliers_detected:,}"
            fraud_score = min(90.0, (outliers_detected / len(df)) * 100 * 20)
        
        analysis_text += f"\n\n**üéØ Recomenda√ß√µes:**"
        analysis_text += f"\n‚Ä¢ Implementar monitoramento em tempo real"
        analysis_text += f"\n‚Ä¢ Configurar alertas para transa√ß√µes suspeitas"
        analysis_text += f"\n‚Ä¢ Revisar regras de neg√≥cio baseadas nos padr√µes encontrados"
        
    else:
        # An√°lise de transa√ß√£o espec√≠fica
        analysis_text = """üõ°Ô∏è **AN√ÅLISE DE TRANSA√á√ÉO ESPEC√çFICA**

**Status:** An√°lise b√°sica realizada
**M√©todo:** Regras heur√≠sticas

**Verifica√ß√µes Realizadas:**
‚Ä¢ Valida√ß√£o de padr√µes b√°sicos
‚Ä¢ An√°lise de consist√™ncia
‚Ä¢ Verifica√ß√£o de limites

**Recomenda√ß√£o:** Para an√°lise mais profunda, fa√ßa upload de dataset hist√≥rico."""
        fraud_score = 25.0  # Score baixo para an√°lise b√°sica
    
    return {
        'response': analysis_text,
        'agent_used': 'fraud_analyzer_simple',
        'analysis_type': 'fraud_detection',
        'confidence': 0.7,
        'fraud_score': fraud_score
    }

# Fun√ß√µes auxiliares para extra√ß√£o de m√©tricas
def extract_fraud_score(text: str) -> float:
    """Extrai score de fraude da resposta da IA"""
    import re
    
    # Procura por padr√µes como "score: 85", "85%", "risco: 0.85"
    patterns = [
        r'score[:\s]+(\d+(?:\.\d+)?)',
        r'(\d+(?:\.\d+)?)%',
        r'risco[:\s]+(\d+(?:\.\d+)?)',
        r'probabilidade[:\s]+(\d+(?:\.\d+)?)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text.lower())
        if match:
            score = float(match.group(1))
            # Normaliza para 0-100
            if score <= 1.0:
                score *= 100
            return min(100.0, max(0.0, score))
    
    # Score padr√£o baseado em palavras-chave
    high_risk_words = ['fraude', 'suspeito', 'an√¥malo', 'irregular', 'alto risco']
    medium_risk_words = ['moderado', 'aten√ß√£o', 'm√©dio']
    low_risk_words = ['normal', 'baixo', 'leg√≠timo']
    
    text_lower = text.lower()
    high_count = sum(1 for word in high_risk_words if word in text_lower)
    medium_count = sum(1 for word in medium_risk_words if word in text_lower)
    low_count = sum(1 for word in low_risk_words if word in text_lower)
    
    if high_count > medium_count + low_count:
        return 75.0
    elif medium_count > low_count:
        return 45.0
    else:
        return 20.0

def determine_risk_level(score: float) -> str:
    """Determina n√≠vel de risco baseado no score"""
    if score >= 80:
        return "critical"
    elif score >= 60:
        return "high"
    elif score >= 40:
        return "medium"
    else:
        return "low"

def extract_patterns(text: str) -> List[str]:
    """Extrai padr√µes detectados da resposta"""
    patterns = []
    
    # Palavras-chave que indicam padr√µes
    keywords = [
        'outlier', 'an√¥malo', 'suspeito', 'irregular',
        'alto valor', 'padr√£o temporal', 'frequ√™ncia elevada',
        'comportamento at√≠pico', 'transa√ß√£o incomum'
    ]
    
    for keyword in keywords:
        if keyword in text.lower():
            patterns.append(keyword.title())
    
    # Se n√£o encontrou padr√µes espec√≠ficos, adiciona gen√©ricos
    if not patterns:
        if 'fraude' in text.lower():
            patterns.append('Padr√£o de fraude detectado')
        else:
            patterns.append('An√°lise comportamental realizada')
    
    return patterns[:5]  # M√°ximo 5 padr√µes

def extract_recommendations(text: str) -> List[str]:
    """Extrai recomenda√ß√µes da resposta"""
    recommendations = []
    
    # Recomenda√ß√µes padr√£o baseadas no conte√∫do
    default_recommendations = [
        'Implementar monitoramento em tempo real',
        'Configurar alertas para transa√ß√µes suspeitas',
        'Revisar regras de neg√≥cio',
        'Aumentar autentica√ß√£o para transa√ß√µes de alto valor',
        'Analisar padr√µes hist√≥ricos'
    ]
    
    # Adiciona recomenda√ß√µes espec√≠ficas se encontradas no texto
    if 'monitoramento' in text.lower():
        recommendations.append('Intensificar monitoramento das transa√ß√µes')
    if 'regra' in text.lower():
        recommendations.append('Revisar e atualizar regras de detec√ß√£o')
    if 'autentica√ß√£o' in text.lower():
        recommendations.append('Implementar autentica√ß√£o adicional')
    
    # Adiciona recomenda√ß√µes padr√£o at√© ter pelo menos 3
    for rec in default_recommendations:
        if len(recommendations) >= 3:
            break
        if rec not in recommendations:
            recommendations.append(rec)
    
    return recommendations

if __name__ == "__main__":
    print("üöÄ Iniciando API Completa - EDA AI Minds")
    print("=" * 50)
    print(f"üìç URL: http://localhost:{PORT}")
    print(f"üìö Docs: http://localhost:{PORT}/docs")
    print(f"üìã ReDoc: http://localhost:{PORT}/redoc")
    print(f"ü§ñ Sistema Multiagente: {'‚úÖ Ativo' if MULTIAGENT_AVAILABLE else '‚ùå Inativo'}")
    if MULTIAGENT_AVAILABLE:
        print("üß† Agentes Dispon√≠veis:")
        print("   ‚Ä¢ Orquestrador Central")
        print("   ‚Ä¢ Analisador de CSV")
        print("   ‚Ä¢ Sistema de Embeddings")
        print("   ‚Ä¢ Detec√ß√£o de Fraude IA")
    print("‚èπÔ∏è Pressione Ctrl+C para parar")
    print()
    
    uvicorn.run(
        "api_completa:app",
        host="0.0.0.0",
        port=PORT,
        reload=True,
        log_level="info"
    )