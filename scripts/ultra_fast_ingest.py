"""Script de ingestÃ£o balanceado - performance + qualidade.

ESTRATÃ‰GIA BALANCEADA:
- Chunks mÃ©dios (250 linhas) para boa granularidade
- Enriquecimento leve preservando contexto
- Processamento assÃ­ncrono (4 workers paralelos)
- Qualidade preservada com velocidade otimizada

ESTIMATIVA: ~2-4 horas (vs 12h anterior)
"""
from __future__ import annotations

import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src.agent.rag_agent import RAGAgent
from src.embeddings.generator import EmbeddingProvider

def main() -> int:
    print("ðŸš€ INGESTÃƒO BALANCEADA creditcard.csv (Performance + Qualidade)")
    
    # ConfiguraÃ§Ãµes balanceadas
    agent = RAGAgent(
        embedding_provider=EmbeddingProvider.SENTENCE_TRANSFORMER,
        chunk_size=2048,  # Chunks textuais mÃ©dios
        chunk_overlap=200,  # Overlap adequado
        csv_chunk_size_rows=250,  # 250 linhas por chunk (balanceado)
        csv_overlap_rows=25,  # 10% de overlap
    )
    
    print(f"âœ… ConfiguraÃ§Ãµes balanceadas:")
    print(f"   â€¢ Linhas por chunk: 250 (qualidade + performance)")
    print(f"   â€¢ Overlap: 25 linhas (10% - preserva contexto)")
    print(f"   â€¢ Enriquecimento: LEVE (contexto essencial)")
    print(f"   â€¢ Processamento: ASSÃNCRONO (4 workers)")
    print(f"   â€¢ Batch embeddings: 100")
    print(f"   â€¢ Batch Supabase: 1000")
    
    result = agent.ingest_csv_file(
        file_path="data/creditcard.csv",
        source_id="creditcard_balanced_v1",
        encoding="utf-8",
        errors="ignore",
    )

    content = result.get("content", "")
    metadata = result.get("metadata", {})

    if metadata.get("error"):
        print("âŒ Falha na ingestÃ£o:")
        print(f"   â€¢ {content}")
        return 1

    print("âœ… IngestÃ£o balanceada concluÃ­da!")
    print(content)
    
    if metadata:
        print("\nðŸ“Š EstatÃ­sticas:")
        print(f"   â€¢ Chunks: {metadata.get('chunks_created')}")
        print(f"   â€¢ Embeddings: {metadata.get('embeddings_generated')}")
        print(f"   â€¢ Armazenados: {metadata.get('embeddings_stored')}")
        print(f"   â€¢ Tempo: {metadata.get('processing_time', 0):.1f}s")
        
        # Calcular velocidade e projeÃ§Ã£o
        chunks = metadata.get('chunks_created', 0)
        time_taken = metadata.get('processing_time', 1)
        if chunks and time_taken:
            speed = chunks / time_taken
            print(f"   â€¢ Velocidade: {speed:.1f} chunks/segundo")
            
            # Estimar total com 285k linhas / 250 por chunk = ~1140 chunks
            total_chunks_estimated = 285000 // 250
            if speed > 0:
                total_time_estimated = total_chunks_estimated / speed
                hours = total_time_estimated / 3600
                print(f"   â€¢ Estimativa total: {hours:.1f} horas para dataset completo")

    return 0

if __name__ == "__main__":
    raise SystemExit(main())